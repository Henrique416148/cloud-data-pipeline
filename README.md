# ‚òÅÔ∏è Cloud Data Pipeline: CoinGecko ‚Üí BigQuery

![Python](https://img.shields.io/badge/Python-3.9+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Google Cloud](https://img.shields.io/badge/Google_Cloud-Platform-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)
![BigQuery](https://img.shields.io/badge/BigQuery-Data_Warehouse-669DF6?style=for-the-badge&logo=google-bigquery&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-Analytics_Dashboard-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)

---

## üìå Vis√£o Geral

Este projeto implementa um **pipeline de Engenharia de Dados end-to-end**, respons√°vel por consumir dados da API p√∫blica da **CoinGecko**, realizar ingest√£o em nuvem e estruturar os dados seguindo a **Arquitetura Medalh√£o (Bronze, Silver e Gold)** no **Google BigQuery**.

O foco principal √© demonstrar:

- Boas pr√°ticas de **engenharia anal√≠tica**
- Uso de **ELT em Data Warehouse**
- **Qualidade, rastreabilidade e observabilidade dos dados**
- Aplica√ß√£o de **m√©tricas financeiras reais** para an√°lise do mercado cripto

---

## üèóÔ∏è Arquitetura da Solu√ß√£o

O pipeline segue o padr√£o **ELT (Extract, Load, Transform)**, priorizando o BigQuery para transforma√ß√µes anal√≠ticas pesadas e escal√°veis.

```mermaid
flowchart LR
    A[CoinGecko API]
    B[Python Ingestion]
    C[BigQuery Bronze]
    D[BigQuery Silver]
    E[BigQuery Gold]
    F[Streamlit Dashboard]

    A --> B
    B --> C
    C --> D
    D --> E
    E --> F

```

### üß© Detalhamento das Etapas do Pipeline

A arquitetura foi desenhada para garantir **idempot√™ncia, rastreabilidade e performance**. Cada camada do Data Warehouse cumpre um papel espec√≠fico na governan√ßa do dado:

#### üì• 1. Camada Bronze (Raw Data)
*Respons√°vel pela ingest√£o bruta e hist√≥rico imut√°vel.*
- **Fonte:** Extra√ß√£o automatizada via Script Python (`requests`).
- **Destino:** Tabela particionada no BigQuery.
- **Estrat√©gia:** *Append-Only*. Todo dado recebido √© gravado com um carimbo de tempo (`ingestion_timestamp`), permitindo auditoria completa e reprocessamento hist√≥rico caso necess√°rio.

#### üõ†Ô∏è 2. Camada Silver (Cleansed & Refined)
*Respons√°vel pela limpeza, deduplica√ß√£o e padroniza√ß√£o.*
- **Tecnologia:** SQL (BigQuery Views).
- **Transforma√ß√µes:**
  - Remo√ß√£o de duplicatas utilizando **Window Functions** (`ROW_NUMBER()`).
  - Convers√£o de tipos de dados (Casting) para formatos nativos do BigQuery.
  - Tratamento de valores nulos e *Data Quality Checks* b√°sicos.
- **Resultado:** Dados confi√°veis e prontos para an√°lise granular.

#### üèÜ 3. Camada Gold (Business Aggregates)
*Respons√°vel pelas m√©tricas de neg√≥cio e KPIs.*
- **Foco:** Performance anal√≠tica.
- **L√≥gica:** Agrega√ß√µes di√°rias para responder perguntas de neg√≥cio.
- **M√©tricas Geradas:**
  - Pre√ßo M√©dio Di√°rio (VWAP simplificado).
  - Volatilidade Intraday (Min/Max).
  - Volumetria de registros (Monitoramento de consist√™ncia).

#### üìä 4. Visualiza√ß√£o (Data Viz)
*Interface final para stakeholders e tomada de decis√£o.*
- **Ferramenta:** **Streamlit** (Python).
- **Funcionalidade:** Conecta diretamente √† camada **Gold** do BigQuery para plotar gr√°ficos de tend√™ncia e tabelas anal√≠ticas, democratizando o acesso aos dados processados.

---

![Visualiza√ß√£o Gold](img/gold-analysis.png)
![Sa√∫de do Pipeline](img/pipeline-health.png)


## üöÄ Diferenciais T√©cnicos

O projeto adota pr√°ticas modernas de Engenharia de Dados:

* ‚úÖ **Arquitetura ELT:** Processamento pesado delegado ao *engine* do BigQuery, reduzindo custos de computa√ß√£o local.
* ‚úÖ **Governan√ßa de Dados:** Separa√ß√£o l√≥gica clara entre dados brutos, tratados e refinados.
* ‚úÖ **Idempot√™ncia:** O pipeline pode ser executado m√∫ltiplas vezes sem duplicar dados na vis√£o final.
* ‚úÖ **Cloud Native:** Utiliza√ß√£o de servi√ßos gerenciados (Serverless) para escalabilidade autom√°tica.

---

## üõ†Ô∏è Stack Tecnol√≥gico

| Categoria | Tecnologia | Uso no Projeto |
| :--- | :--- | :--- |
| **Linguagem** | ![Python](https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=python&logoColor=white) | Script de extra√ß√£o e App de Visualiza√ß√£o |
| **Cloud** | ![Google Cloud](https://img.shields.io/badge/Google_Cloud-4285F4?style=flat-square&logo=google-cloud&logoColor=white) | Plataforma de Nuvem |
| **Warehouse** | ![BigQuery](https://img.shields.io/badge/BigQuery-669DF6?style=flat-square&logo=google-bigquery&logoColor=white) | Armazenamento e Processamento SQL |
| **Dashboard** | ![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=flat-square&logo=streamlit&logoColor=white) | Front-end de Dados |
| **Controle** | ![Git](https://img.shields.io/badge/Git-F05032?style=flat-square&logo=git&logoColor=white) | Versionamento de C√≥digo |

---

## üìà Insights de Neg√≥cio

Al√©m da engenharia, o projeto entrega valor anal√≠tico respondendo a perguntas como:
1.  *Qual a tend√™ncia de pre√ßo do Bitcoin nos √∫ltimos 30 dias?*
2.  *Qual foi a volatilidade (diferen√ßa entre m√≠nima e m√°xima) de ontem?*
3.  *O pipeline de dados sofreu alguma queda de volumetria recentemente?*

---

## ‚öôÔ∏è Como Executar Localmente


```bash
# 1. Clone o reposit√≥rio
git clone [https://github.com/Henrique416148/cloud-data-pipeline.git](https://github.com/Henrique416148/cloud-data-pipeline.git)

# 2. Instale as depend√™ncias
pip install -r requirements.txt

# 3. Configure as credenciais do GCP (Service Account)
export GOOGLE_APPLICATION_CREDENTIALS="path/to/your/key.json"

# 4. Execute a ingest√£o
python src/ingestion.py

# 5. (Opcional) Rode o dashboard
streamlit run src/app.py
```

üëã Sobre Mim
<div align="center"> <h2>Luis Henrique</h2> <h4>Data Engineer | Analytics | Cloud</h4> <p><em>"Transformando dados brutos em insights acion√°veis atrav√©s de engenharia robusta."</em></p> <p> <a href="https://linkedin.com/in/luis-henrique-dos-ribeiro-991aa8250"> <img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white"/> </a> </p> </div> ```
